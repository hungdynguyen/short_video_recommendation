{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm \n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1984e76",
   "metadata": {},
   "source": [
    "# Video Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CẤU HÌNH ---\n",
    "input_folder = r'D:\\learn\\giaotrinh\\ky7\\CV\\final\\downloads\\scripts'\n",
    "output_feature_file = r'D:\\learn\\giaotrinh\\ky7\\CV\\final\\MMRec\\data\\text_features_minilm_384d.npy'\n",
    "output_id_file = r'D:\\learn\\giaotrinh\\ky7\\CV\\final\\MMRec\\data\\text_ids.npy' \n",
    "\n",
    "# 1. Tải Model Transformer nhẹ\n",
    "print(\"Loading Sentence-Transformer model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Quét file và Sắp xếp (QUAN TRỌNG NHẤT)\n",
    "# Lấy tất cả file .txt\n",
    "files = [f for f in os.listdir(input_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Sắp xếp danh sách file theo tên (alphabet/numerical)\n",
    "# Điều này đảm bảo: file '000123.txt' sẽ được xử lý trước '000124.txt'\n",
    "# Nếu bên Video bạn cũng sort như thế này, thì 2 bên sẽ khớp nhau 100%\n",
    "files.sort() \n",
    "\n",
    "print(f\"Found {len(files)} text files. Processing in sorted order...\")\n",
    "\n",
    "# 3. Đọc dữ liệu\n",
    "all_texts = []\n",
    "all_ids = []\n",
    "\n",
    "for filename in tqdm(files):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    \n",
    "    # Lấy ID từ tên file (bỏ đuôi .txt)\n",
    "    # Ví dụ: '102394.txt' -> '102394'\n",
    "    file_id = filename.replace('.txt', '')\n",
    "    all_ids.append(file_id)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "        # Nếu file rỗng thì để chuỗi rỗng (model vẫn xử lý được)\n",
    "        all_texts.append(content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        all_texts.append(\"\") # Append rỗng để giữ đúng index\n",
    "\n",
    "# 4. Trích xuất đặc trưng (Batch Processing)\n",
    "print(\"Encoding texts...\")\n",
    "# batch_size=64 hoặc 128 tùy vào VRAM của GPU trên Kaggle\n",
    "features_array = model.encode(all_texts, batch_size=128, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# 5. Lưu kết quả\n",
    "# Lưu ma trận đặc trưng\n",
    "np.save(output_feature_file, features_array)\n",
    "\n",
    "# Lưu danh sách ID (để sau này map với item)\n",
    "np.save(output_id_file, np.array(all_ids))\n",
    "\n",
    "print(\"--- HOÀN TẤT ---\")\n",
    "print(f\"Saved features shape: {features_array.shape}\") # (Số lượng file, 384)\n",
    "print(f\"Saved IDs list shape: {len(all_ids)}\")\n",
    "print(f\"Files saved: {output_feature_file} and {output_id_file}\")\n",
    "\n",
    "# Kiểm tra thử 3 ID đầu tiên\n",
    "print(\"First 3 IDs processed:\", all_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CẤU HÌNH ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "video_dir1 = r\"D:\\learn\\giaotrinh\\ky7\\CV\\final\\downloads\\videos\" \n",
    "output_feature_file = r\"D:\\learn\\giaotrinh\\ky7\\CV\\final\\MMRec\\data\\video_features_uniform_concat.npy\"\n",
    "output_id_file = r\"D:\\learn\\giaotrinh\\ky7\\CV\\final\\MMRec\\data\\video_ids.npy\"\n",
    "\n",
    "# --- HÀM HỖ TRỢ ---\n",
    "def _load_video(video_dir, video_id):\n",
    "    \"\"\"Load and uniformly sample 4 frames from video.\"\"\"\n",
    "    num_frames = 4\n",
    "    video_name = str(video_id) + \".mp4\"\n",
    "    path = os.path.join(video_dir, video_name)\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Cannot open video {video_name}\")\n",
    "        \n",
    "    NumFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Chiến lược lấy mẫu\n",
    "    if NumFrames < num_frames:\n",
    "        # Nếu video quá ngắn hoặc lỗi đọc frame, trả về 0\n",
    "        if NumFrames <= 0:\n",
    "             return torch.zeros(num_frames, 3, 224, 224)\n",
    "        indices = np.linspace(0, NumFrames - 1, num_frames, dtype=int)\n",
    "    else:\n",
    "        indices = np.linspace(0, NumFrames - 1, num_frames, dtype=int)\n",
    "\n",
    "    sampled_frms = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        rval, frame = cap.read()\n",
    "        if rval:\n",
    "            # Convert BGR (OpenCV) to RGB (PIL/PyTorch)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            img = img.resize((224, 224))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                     std=[0.229, 0.224, 0.225])(img)\n",
    "            sampled_frms.append(img)\n",
    "        else:\n",
    "            sampled_frms.append(torch.zeros(3, 224, 224))\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Stack lại: [4, 3, 224, 224]\n",
    "    return torch.stack(sampled_frms, dim=0)\n",
    "\n",
    "class GridFeatBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GridFeatBackbone, self).__init__()\n",
    "        # Load ViT\n",
    "        self.net = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "        self.net.heads = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size * num_frames, 3, 224, 224]\n",
    "        return self.net(x)\n",
    "\n",
    "# --- QUY TRÌNH CHÍNH ---\n",
    "\n",
    "# 1. Lấy danh sách file và SẮP XẾP CHUẨN (String Sort)\n",
    "# Lưu ý: Dùng sort() thường để khớp với code Text bên trên (001.txt, 002.txt...)\n",
    "files = [f for f in os.listdir(video_dir1) if f.endswith('.mp4')]\n",
    "files.sort() \n",
    "\n",
    "print(f\"Found {len(files)} videos. Starting extraction on {device}...\")\n",
    "\n",
    "# 2. Khởi tạo model\n",
    "model = GridFeatBackbone().to(device)\n",
    "model.eval() # Quan trọng: Chuyển sang chế độ đánh giá (tắt dropout)\n",
    "\n",
    "all_features = []\n",
    "processed_ids = []\n",
    "\n",
    "# 3. Vòng lặp với tqdm gọn gàng\n",
    "# desc: Tiêu đề thanh loading\n",
    "for f in tqdm(files, desc=\"Extracting Visual Features\"):\n",
    "    video_id = f.replace('.mp4', '') # Lấy ID, ví dụ \"123456\"\n",
    "    \n",
    "    try:\n",
    "        # Load frames: [4, 3, 224, 224]\n",
    "        frms = _load_video(video_dir1, video_id)\n",
    "        frms = frms.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # ViT nhận batch. Ở đây 4 frame coi như batch=4\n",
    "            out = model(frms) # [4, 768]\n",
    "            \n",
    "            # Flatten: [4, 768] -> [1, 3072]\n",
    "            # view(1, -1) nhanh hơn và gọn hơn cách dùng torch.cat loop cũ\n",
    "            video_feature = out.reshape(1, -1) \n",
    "            \n",
    "        # Move về CPU để lưu RAM\n",
    "        all_features.append(video_feature.cpu().numpy())\n",
    "        processed_ids.append(video_id)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Dùng tqdm.write để in lỗi không bị vỡ thanh loading\n",
    "        tqdm.write(f\"Error processing {video_id}: {e}\")\n",
    "        # Nếu lỗi, thêm vector 0 để giữ đúng index (quan trọng để khớp với Text)\n",
    "        all_features.append(np.zeros((1, 768 * 4), dtype=np.float32))\n",
    "        processed_ids.append(video_id)\n",
    "\n",
    "# 4. Lưu file\n",
    "if len(all_features) > 0:\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    np.save(output_feature_file, all_features)\n",
    "    np.save(output_id_file, np.array(processed_ids)) # Lưu luôn ID cho chắc\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "    print(f\"Features shape: {all_features.shape}\") # (N, 3072)\n",
    "    print(f\"Saved to: {output_feature_file}\")\n",
    "else:\n",
    "    print(\"No features extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba4c7f",
   "metadata": {},
   "source": [
    "# User feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebbcd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "interact_df = pd.read_csv(r'D:\\learn\\giaotrinh\\ky7\\CV\\final\\data\\raw_items\\interaction_final.csv')\n",
    "len(interact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f902b360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'pid', 'author_id', 'category_id', 'category_level',\n",
       "       'parent_id', 'root_id', 'exposed_time', 'author_fans_count',\n",
       "       'watch_time', 'duration', 'cvm_like', 'click', 'comment', 'follow',\n",
       "       'collect', 'forward', 'hate', 'tag_name', 'title', 'p_hour', 'p_date',\n",
       "       'gender', 'age', 'mod_price', 'fre_city', 'fre_community_type',\n",
       "       'fre_city_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3a7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['user_id', 'pid', 'exposed_time', 'p_date', 'p_hour', 'watch_time', 'cvm_like', 'comment', 'follow', \n",
    "                   'collect', 'forward', 'hate', 'gender', 'age', 'mod_price', 'fre_city', 'fre_community_type', 'fre_city_level', 'duration']\n",
    "interact_df = interact_df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf53095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6792)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6849f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df = interact_df.drop_duplicates()\n",
    "len(interact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b330baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_df.to_csv('interaction_final_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbe20ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1279bc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.1117647058823525)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.groupby('user_id').size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680b9ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.041176470588235\n"
     ]
    }
   ],
   "source": [
    "distinct_per_user = interact_df.groupby('user_id')['pid'].nunique()\n",
    "mean_distinct = distinct_per_user.mean()\n",
    "print(mean_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7befa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pid</th>\n",
       "      <th>exposed_time</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_hour</th>\n",
       "      <th>watch_time</th>\n",
       "      <th>cvm_like</th>\n",
       "      <th>comment</th>\n",
       "      <th>follow</th>\n",
       "      <th>collect</th>\n",
       "      <th>forward</th>\n",
       "      <th>hate</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>mod_price</th>\n",
       "      <th>fre_city</th>\n",
       "      <th>fre_community_type</th>\n",
       "      <th>fre_city_level</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366</td>\n",
       "      <td>66812</td>\n",
       "      <td>1663337736</td>\n",
       "      <td>20220916</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>69</td>\n",
       "      <td>899</td>\n",
       "      <td>淮安</td>\n",
       "      <td>城区</td>\n",
       "      <td>三线城市</td>\n",
       "      <td>36.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>366</td>\n",
       "      <td>57413</td>\n",
       "      <td>1663337682</td>\n",
       "      <td>20220916</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>69</td>\n",
       "      <td>899</td>\n",
       "      <td>淮安</td>\n",
       "      <td>城区</td>\n",
       "      <td>三线城市</td>\n",
       "      <td>268.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>366</td>\n",
       "      <td>59348</td>\n",
       "      <td>1663337736</td>\n",
       "      <td>20220916</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>69</td>\n",
       "      <td>899</td>\n",
       "      <td>淮安</td>\n",
       "      <td>城区</td>\n",
       "      <td>三线城市</td>\n",
       "      <td>255.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2494</td>\n",
       "      <td>52190</td>\n",
       "      <td>1663336889</td>\n",
       "      <td>20220916</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>55</td>\n",
       "      <td>2699</td>\n",
       "      <td>巴音郭楞蒙古自治州</td>\n",
       "      <td>unknown</td>\n",
       "      <td>五线城市</td>\n",
       "      <td>215.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2494</td>\n",
       "      <td>68485</td>\n",
       "      <td>1663337405</td>\n",
       "      <td>20220916</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>55</td>\n",
       "      <td>2699</td>\n",
       "      <td>巴音郭楞蒙古自治州</td>\n",
       "      <td>unknown</td>\n",
       "      <td>五线城市</td>\n",
       "      <td>183.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id    pid  exposed_time    p_date  p_hour  watch_time  cvm_like  \\\n",
       "0       366  66812    1663337736  20220916      22          29     False   \n",
       "15      366  57413    1663337682  20220916      22           7     False   \n",
       "27      366  59348    1663337736  20220916      22          21     False   \n",
       "39     2494  52190    1663336889  20220916      22           5     False   \n",
       "49     2494  68485    1663337405  20220916      22          17     False   \n",
       "\n",
       "    comment  follow  collect  forward   hate gender  age  mod_price  \\\n",
       "0     False   False    False    False  False      F   69        899   \n",
       "15    False   False    False    False  False      F   69        899   \n",
       "27    False   False    False    False  False      F   69        899   \n",
       "39    False   False    False    False  False      M   55       2699   \n",
       "49    False   False    False    False  False      M   55       2699   \n",
       "\n",
       "     fre_city fre_community_type fre_city_level  duration  \n",
       "0          淮安                 城区           三线城市    36.816  \n",
       "15         淮安                 城区           三线城市   268.626  \n",
       "27         淮安                 城区           三线城市   255.346  \n",
       "39  巴音郭楞蒙古自治州            unknown           五线城市   215.433  \n",
       "49  巴音郭楞蒙古自治州            unknown           五线城市   183.833  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c08c3e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'pid', 'exposed_time', 'p_date', 'p_hour', 'watch_time',\n",
       "       'cvm_like', 'comment', 'follow', 'collect', 'forward', 'hate', 'gender',\n",
       "       'age', 'mod_price', 'fre_city', 'fre_community_type', 'fre_city_level',\n",
       "       'duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce1efe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pid</th>\n",
       "      <th>exposed_time</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_hour</th>\n",
       "      <th>watch_time</th>\n",
       "      <th>age</th>\n",
       "      <th>mod_price</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7491.000000</td>\n",
       "      <td>7491.000000</td>\n",
       "      <td>7.491000e+03</td>\n",
       "      <td>7491.0</td>\n",
       "      <td>7491.000000</td>\n",
       "      <td>7491.000000</td>\n",
       "      <td>7491.000000</td>\n",
       "      <td>7491.000000</td>\n",
       "      <td>7491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4748.159258</td>\n",
       "      <td>61420.417701</td>\n",
       "      <td>1.663315e+09</td>\n",
       "      <td>20220916.0</td>\n",
       "      <td>15.688159</td>\n",
       "      <td>70.863970</td>\n",
       "      <td>45.594046</td>\n",
       "      <td>2188.335469</td>\n",
       "      <td>172.217237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2899.808565</td>\n",
       "      <td>30601.328875</td>\n",
       "      <td>2.020604e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.619387</td>\n",
       "      <td>85.214609</td>\n",
       "      <td>17.043753</td>\n",
       "      <td>2026.743777</td>\n",
       "      <td>130.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.663264e+09</td>\n",
       "      <td>20220916.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2255.000000</td>\n",
       "      <td>34115.000000</td>\n",
       "      <td>1.663300e+09</td>\n",
       "      <td>20220916.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>72.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4716.000000</td>\n",
       "      <td>66191.000000</td>\n",
       "      <td>1.663320e+09</td>\n",
       "      <td>20220916.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>149.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7192.000000</td>\n",
       "      <td>88982.500000</td>\n",
       "      <td>1.663333e+09</td>\n",
       "      <td>20220916.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>2499.000000</td>\n",
       "      <td>259.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9939.000000</td>\n",
       "      <td>100959.000000</td>\n",
       "      <td>1.663343e+09</td>\n",
       "      <td>20220916.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17799.000000</td>\n",
       "      <td>821.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id            pid  exposed_time      p_date       p_hour  \\\n",
       "count  7491.000000    7491.000000  7.491000e+03      7491.0  7491.000000   \n",
       "mean   4748.159258   61420.417701  1.663315e+09  20220916.0    15.688159   \n",
       "std    2899.808565   30601.328875  2.020604e+04         0.0     5.619387   \n",
       "min       2.000000      46.000000  1.663264e+09  20220916.0     2.000000   \n",
       "25%    2255.000000   34115.000000  1.663300e+09  20220916.0    11.000000   \n",
       "50%    4716.000000   66191.000000  1.663320e+09  20220916.0    17.000000   \n",
       "75%    7192.000000   88982.500000  1.663333e+09  20220916.0    21.000000   \n",
       "max    9939.000000  100959.000000  1.663343e+09  20220916.0    23.000000   \n",
       "\n",
       "        watch_time          age     mod_price     duration  \n",
       "count  7491.000000  7491.000000   7491.000000  7491.000000  \n",
       "mean     70.863970    45.594046   2188.335469   172.217237  \n",
       "std      85.214609    17.043753   2026.743777   130.208301  \n",
       "min       0.000000    20.000000    400.000000     6.000000  \n",
       "25%       9.000000    32.000000   1099.000000    72.680000  \n",
       "50%      35.000000    45.000000   1599.000000   149.004000  \n",
       "75%     107.000000    59.000000   2499.000000   259.492000  \n",
       "max     612.000000    79.000000  17799.000000   821.800000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a17fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          False  True \n",
      "cvm_like   7275    216\n",
      "comment    7479     12\n",
      "follow     7402     89\n",
      "collect    7463     28\n",
      "forward    7479     12\n",
      "hate       7491      0\n"
     ]
    }
   ],
   "source": [
    "# Danh sách các cột\n",
    "binary_cols = ['cvm_like', 'click', 'comment', 'follow', 'collect', 'forward', 'hate']\n",
    "\n",
    "# Lọc chỉ lấy các cột có trong df\n",
    "existing_cols = [c for c in binary_cols if c in interact_df.columns]\n",
    "\n",
    "# Dùng apply để tính value_counts cho nhiều cột cùng lúc\n",
    "summary_table = interact_df[existing_cols].apply(pd.Series.value_counts).T\n",
    "\n",
    "print(summary_table.fillna(0).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c8b3dc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'click'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learn\\giaotrinh\\ky7\\CV\\final\\cv_final_venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'click'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m positive_df = interact_df[\n\u001b[32m      2\u001b[39m     (interact_df[\u001b[33m'\u001b[39m\u001b[33mwatch_time\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m30\u001b[39m) | \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     (\u001b[43minteract_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclick\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[32m1\u001b[39m) |\n\u001b[32m      4\u001b[39m     (interact_df[\u001b[33m'\u001b[39m\u001b[33mcvm_like\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m ].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learn\\giaotrinh\\ky7\\CV\\final\\cv_final_venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learn\\giaotrinh\\ky7\\CV\\final\\cv_final_venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'click'"
     ]
    }
   ],
   "source": [
    "positive_df = interact_df[\n",
    "    (interact_df['watch_time'] > 30) | \n",
    "    (interact_df['click'] == 1) |\n",
    "    (interact_df['cvm_like'] == 1)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf39a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserTower(tf.keras.Model):\n",
    "    def __init__(self, user_ids, city_vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Embedding cho User ID\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(user_ids) + 1, 32)\n",
    "        ])\n",
    "\n",
    "        # 2. Embedding cho City (Categorical Feature)\n",
    "        self.city_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=city_vocab, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(city_vocab) + 1, 16)\n",
    "        ])\n",
    "\n",
    "        # 3. Xử lý Age (Numerical Feature)\n",
    "        # Chuẩn hóa age về khoảng nhỏ (chia cho 100 hoặc dùng Normalization layer)\n",
    "        self.normalized_age = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "        # 4. Dense Layer cuối cùng để trộn tất cả\n",
    "        self.dense = tf.keras.layers.Dense(32) # Output dimension = 32\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Lấy embedding các phần\n",
    "        u_vec = self.user_embedding(inputs[\"user_id\"])\n",
    "        c_vec = self.city_embedding(inputs[\"fre_city\"])\n",
    "        \n",
    "        # Age cần reshape để nối được\n",
    "        age_val = tf.reshape(self.normalized_age(inputs[\"age\"]), (-1, 1))\n",
    "\n",
    "        # Nối tất cả lại: [UserID_32 + City_16 + Age_1]\n",
    "        concatenated = tf.concat([u_vec, c_vec, age_val], axis=1)\n",
    "        \n",
    "        # Qua lớp Dense để ra vector cuối cùng (32 chiều)\n",
    "        return self.dense(concatenated)\n",
    "\n",
    "# Lấy vocab để init model\n",
    "unique_user_ids = np.unique(positive_df['user_id'].astype(str).values)\n",
    "unique_cities = np.unique(positive_df['fre_city'].astype(str).values)\n",
    "\n",
    "user_model = UserTower(unique_user_ids, unique_cities)\n",
    "# Adapt layer normalization cho age\n",
    "user_model.normalized_age.adapt(positive_df['age'].fillna(0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "    def __init__(self, item_ids):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Embedding cho PID (ID Video)\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=item_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(item_ids) + 1, 32)\n",
    "        ])\n",
    "\n",
    "        # 2. Xử lý Vector Content (Input size 128 -> Project xuống 32)\n",
    "        self.content_projection = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "\n",
    "        # 3. Dense trộn ID và Content\n",
    "        self.dense = tf.keras.layers.Dense(32) # Output dimension = 32 (Phải khớp User Tower)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs[\"pid\"] và inputs[\"item_vector\"]\n",
    "        \n",
    "        id_vec = self.item_embedding(inputs[\"pid\"])\n",
    "        content_vec = self.content_projection(inputs[\"item_vector\"])\n",
    "\n",
    "        # Cộng hoặc Nối. Ở đây mình dùng Nối (Concat) rồi Dense\n",
    "        concatenated = tf.concat([id_vec, content_vec], axis=1)\n",
    "        \n",
    "        return self.dense(concatenated)\n",
    "\n",
    "unique_item_ids = np.unique(df_video['pid'].astype(str).values)\n",
    "item_model = ItemTower(unique_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77387968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeRetrievalModel(tfrs.models.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        \n",
    "        # Task Retrieval: Tự động tính Loss và Metrics (Top-K accuracy)\n",
    "        # items_ds.batch(128).map(item_model) nghĩa là:\n",
    "        # Khi tính toán, nó sẽ lấy toàn bộ video trong kho, chạy qua ItemTower \n",
    "        # để tạo ra index các vector ứng viên.\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items_ds.map(item_model) \n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        # 1. Tính User Vector (Query)\n",
    "        user_embeddings = self.user_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"age\": features[\"age\"],\n",
    "            \"fre_city\": features[\"fre_city\"]\n",
    "        })\n",
    "\n",
    "        # 2. Tính Item Vector (Candidate) - Của chính video đang xem (Positive)\n",
    "        positive_movie_embeddings = self.item_model({\n",
    "            \"pid\": features[\"pid\"],\n",
    "            \"item_vector\": features[\"item_vector\"]\n",
    "        })\n",
    "\n",
    "        # 3. Tính Loss (Contrastive Loss / Softmax Loss)\n",
    "        # TFRS sẽ tự lấy các items khác trong batch làm Negative Samples (In-batch negative)\n",
    "        return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo model tổng\n",
    "model = YouTubeRetrievalModel(user_model, item_model)\n",
    "\n",
    "# Compile (Dùng Adagrad hoặc Adam)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train\n",
    "# epoch nên để thấp (3-5) nếu dữ liệu lớn để tránh overfitting\n",
    "model.fit(train_ds, epochs=5, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tạo công cụ tìm kiếm BruteForce (quét cạn - chính xác 100% nhưng chậm nếu > 1 triệu item)\n",
    "# Nếu dữ liệu lớn, hãy dùng tfrs.layers.factorized_top_k.ScaNN (cần cài thêm thư viện scann)\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "\n",
    "# 2. Đưa toàn bộ Item vào index (đã vector hóa)\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((\n",
    "      items_ds.map(lambda x: x[\"pid\"]), # Chỉ lấy ID để trả về\n",
    "      items_ds.map(model.item_model)    # Vector tương ứng\n",
    "  ))\n",
    ")\n",
    "\n",
    "# 3. Test thử gợi ý\n",
    "# Lấy 1 user mẫu từ tập test\n",
    "sample_user = {\n",
    "    \"user_id\": tf.constant([\"12345\"]), # Giả sử ID 12345\n",
    "    \"age\": tf.constant([25.0]),\n",
    "    \"fre_city\": tf.constant([\"Hanoi\"])\n",
    "}\n",
    "\n",
    "# Lấy 3 gợi ý tốt nhất\n",
    "_, titles = index(sample_user, k=3)\n",
    "\n",
    "print(f\"Top 3 videos for user 12345: {titles[0].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87ec861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filter, sys.path: ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', 'd:\\\\learn\\\\giaotrinh\\\\ky7\\\\CV\\\\final\\\\cv_final_venv', '', 'd:\\\\learn\\\\giaotrinh\\\\ky7\\\\CV\\\\final\\\\cv_final_venv\\\\Lib\\\\site-packages']\n",
      "Removing invalid path from sys.path: \n",
      "After filter, sys.path: ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', 'd:\\\\learn\\\\giaotrinh\\\\ky7\\\\CV\\\\final\\\\cv_final_venv', 'd:\\\\learn\\\\giaotrinh\\\\ky7\\\\CV\\\\final\\\\cv_final_venv\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# In toàn bộ sys.path để debug\n",
    "print(\"Before filter, sys.path:\", sys.path)\n",
    "\n",
    "# Lọc: giữ lại phần tử là string đường dẫn hợp lệ (non-empty)\n",
    "new_paths = []\n",
    "for p in sys.path:\n",
    "    if isinstance(p, str) and p:\n",
    "        new_paths.append(p)\n",
    "    else:\n",
    "        print(\"Removing invalid path from sys.path:\", p)\n",
    "\n",
    "sys.path[:] = new_paths\n",
    "\n",
    "print(\"After filter, sys.path:\", sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd0e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_final_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
